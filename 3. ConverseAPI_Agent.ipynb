{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bfb4280-0a46-4715-aaf3-9359b7a63b65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_aws in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.1.6)\n",
      "Collecting langchain_aws\n",
      "  Downloading langchain_aws-0.1.9-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: boto3<1.35.0,>=1.34.131 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain_aws) (1.34.140)\n",
      "Collecting langchain-core<0.3,>=0.2.6 (from langchain_aws)\n",
      "  Downloading langchain_core-0.2.11-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain_aws) (1.26.4)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.140 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<1.35.0,>=1.34.131->langchain_aws) (1.34.140)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<1.35.0,>=1.34.131->langchain_aws) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<1.35.0,>=1.34.131->langchain_aws) (0.10.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.6->langchain_aws) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.6->langchain_aws) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.6->langchain_aws) (0.1.75)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.6->langchain_aws) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.6->langchain_aws) (2.7.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.6->langchain_aws) (8.2.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.140->boto3<1.35.0,>=1.34.131->langchain_aws) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.140->boto3<1.35.0,>=1.34.131->langchain_aws) (2.2.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.6->langchain_aws) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.6->langchain_aws) (3.10.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.6->langchain_aws) (2.31.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.6->langchain_aws) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.6->langchain_aws) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.6->langchain_aws) (4.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.140->boto3<1.35.0,>=1.34.131->langchain_aws) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.6->langchain_aws) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.6->langchain_aws) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.6->langchain_aws) (2024.2.2)\n",
      "Downloading langchain_aws-0.1.9-py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.2.11-py3-none-any.whl (337 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.4/337.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langchain-core, langchain_aws\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.2.5\n",
      "    Uninstalling langchain-core-0.2.5:\n",
      "      Successfully uninstalled langchain-core-0.2.5\n",
      "  Attempting uninstall: langchain_aws\n",
      "    Found existing installation: langchain-aws 0.1.6\n",
      "    Uninstalling langchain-aws-0.1.6:\n",
      "      Successfully uninstalled langchain-aws-0.1.6\n",
      "Successfully installed langchain-core-0.2.11 langchain_aws-0.1.9\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f41b7e8-6385-4ec8-b76e-cfca34892838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c8c791a-11c2-4393-b038-fad2b2510538",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import random\n",
    "\n",
    "from botocore.config import Config\n",
    "config = Config(\n",
    "    # region_name=random.choice(['us-west-2','us-east-1']),\n",
    "    # region_name='us-east-1',\n",
    "    read_timeout=600, ## Timeout 시간 조정\n",
    "    retries = dict(\n",
    "        max_attempts = 8 ## Retry 횟수 조정\n",
    "    )\n",
    ")\n",
    "\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "## https://api.python.langchain.com/en/latest/chat_models/langchain_aws.chat_models.bedrock.ChatBedrock.html\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    region_name=random.choice(['us-west-2','us-east-1']),\n",
    "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\", #파운데이션 모델 지정\n",
    "    max_tokens=1024,\n",
    "    temperature=0,\n",
    "    config=config\n",
    ") #Claude 속성 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac5b9017-bede-46d1-9f15-17115c102135",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = BedrockEmbeddings() #Titan 임베딩 클라이언트를 생성합니다.\n",
    "\n",
    "pdf_path = \"2022-Shareholder-Letter.pdf\" #이 이름을 가진 로컬 PDF 파일을 가정합니다.\n",
    "\n",
    "loader = PyPDFLoader(file_path=pdf_path) #PDF 파일 로드하기\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter( #텍스트 분할기 만들기\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"], #(1) 단락, (2) 줄, (3) 문장 또는 (4) 단어 순서로 청크를 분할합니다.\n",
    "    chunk_size=1000, #위의 구분 기호를 사용하여 1000자 청크로 나눕니다.\n",
    "    chunk_overlap=100 #이전 청크와 겹칠 수 있는 문자 수입니다.\n",
    ")\n",
    "\n",
    "index_creator = VectorstoreIndexCreator( #벡터 스토어 팩토리 만들기\n",
    "    vectorstore_cls=FAISS, #데모 목적으로 인메모리 벡터 저장소를 사용합니다.\n",
    "    embedding=embeddings, #Titan 임베딩 사용\n",
    "    text_splitter=text_splitter, #재귀적 텍스트 분할기 사용하기\n",
    ")\n",
    "\n",
    "index_from_loader = index_creator.from_loaders([loader]) #로드된 PDF에서 벡터 스토어 인덱스를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97ef6945-aa17-48af-9b5e-d110c14d91e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    human_prefix = 'User', \n",
    "    ai_prefix='Assistant', \n",
    "    memory_key=\"chat_history\", \n",
    "    return_messages=True\n",
    ") #이전 메시지의 기록을 유지합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b434f08f-ba19-4c0b-a5da-ea546272dc59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_text = '회사의 Generative AI 전략은 무엇인가요?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c711508-fd45-4b20-8f89-2e98744698f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아마존은 Generative AI, 특히 대규모 언어 모델(LLM)에 상당한 투자를 하고 있습니다. 주요 전략은 다음과 같습니다:\\n\\n1. 자체 LLM 개발 및 모든 고객 경험 개선을 위한 활용\\n아마존은 자체 LLM을 개발 중이며, 이를 통해 소비자, 판매자, 브랜드, 크리에이터 등 모든 고객 경험을 혁신하고자 합니다.\\n\\n2. AWS를 통한 Generative AI 민주화\\nAWS는 Trainium, Inferentia 등 가격 대비 성능이 우수한 ML 칩을 제공하여 기업들이 LLM을 저렴하게 학습하고 운영할 수 있도록 지원합니다. 또한 CodeWhisperer 등 Generative AI 애플리케이션도 제공합니다.\\n\\n3. 광고 및 추천 시스템 고도화\\n아마존은 LLM과 머신러닝을 활용하여 광고 및 제품 추천 알고리즘을 지속적으로 개선하고 있습니다.\\n\\n요약하면 아마존은 자체 LLM 개발, AWS 클라우드 서비스를 통한 Generative AI 민주화, 그리고 자사 서비스의 광고/추천 고도화를 위해 Generative AI에 적극 투자하고 있습니다.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "conversation_with_retrieval = ConversationalRetrievalChain.from_llm(\n",
    "    llm, \n",
    "    index_from_loader.vectorstore.as_retriever(), \n",
    "    memory=memory\n",
    ")\n",
    "chat_response = conversation_with_retrieval.invoke({\"question\": input_text}) #사용자 메시지, 기록 및 지식을 모델에 전달합니다.\n",
    "\n",
    "chat_response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e2f393a-82e1-40ff-a0c0-3ae1838507fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_text = 'LLM 기반 광고/추천 시스템 고도화에 대해 좀 더 자세히 알려줄 수 있어?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e76adc12-5498-4769-bde1-eea5a438ce4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'제프 베조스의 연례 주주 서한에서 언급된 내용을 종합해보면, 아마존은 LLM(Large Language Model)과 생성형 AI 기술을 활용하여 광고 및 제품 추천 시스템을 고도화할 계획인 것으로 보입니다.\\n\\n구체적으로는 다음과 같은 방향으로 진행될 것으로 예상됩니다:\\n\\n1. LLM을 활용하여 고객의 검색 의도와 쇼핑 행동을 더 잘 이해하고, 이를 바탕으로 관련성 높은 광고와 제품을 추천하는 기능 개선\\n\\n2. 생성형 AI 모델을 활용하여 고객, 판매자, 브랜드, 크리에이터 등 다양한 이해관계자를 위한 맞춤형 경험 제공\\n\\n3. AWS 클라우드 상에서 LLM 및 생성형 AI 모델을 효율적으로 학습하고 운영할 수 있는 인프라 및 서비스 제공\\n\\n4. 개발자 생산성 향상을 위한 코드 제안 등 LLM 기반 개발자 도구 활용\\n\\n아마존은 이러한 LLM과 생성형 AI 기술 활용을 통해 고객 경험 혁신, 광고 효율 제고, 개발자 생산성 향상 등의 효과를 기대하고 있는 것으로 보입니다.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_retrieval = ConversationalRetrievalChain.from_llm(\n",
    "    llm, \n",
    "    index_from_loader.vectorstore.as_retriever(), \n",
    "    memory=memory\n",
    ")\n",
    "chat_response = conversation_with_retrieval.invoke({\"question\": input_text}) #사용자 메시지, 기록 및 지식을 모델에 전달합니다.\n",
    "\n",
    "chat_response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93a9d90b-27cb-4719-8a09-2caefff8c1cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferWindowMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='회사의 Generative AI 전략은 무엇인가요?'), AIMessage(content='아마존은 Generative AI, 특히 대규모 언어 모델(LLM)에 상당한 투자를 하고 있습니다. 주요 전략은 다음과 같습니다:\\n\\n1. 자체 LLM 개발 및 모든 고객 경험 개선을 위한 활용\\n아마존은 자체 LLM을 개발 중이며, 이를 통해 소비자, 판매자, 브랜드, 크리에이터 등 모든 고객 경험을 혁신하고자 합니다.\\n\\n2. AWS를 통한 Generative AI 민주화\\nAWS는 Trainium, Inferentia 등 가격 대비 성능이 우수한 ML 칩을 제공하여 기업들이 LLM을 저렴하게 학습하고 운영할 수 있도록 지원합니다. 또한 CodeWhisperer 등 Generative AI 애플리케이션도 제공합니다.\\n\\n3. 광고 및 추천 시스템 고도화\\n아마존은 LLM과 머신러닝을 활용하여 광고 및 제품 추천 알고리즘을 지속적으로 개선하고 있습니다.\\n\\n요약하면 아마존은 자체 LLM 개발, AWS 클라우드 서비스를 통한 Generative AI 민주화, 그리고 자사 서비스의 광고/추천 고도화를 위해 Generative AI에 적극 투자하고 있습니다.'), HumanMessage(content='LLM 기반 광고/추천 시스템 고도화에 대해 좀 더 자세히 알려줄 수 있어?'), AIMessage(content='제프 베조스의 연례 주주 서한에서 언급된 내용을 종합해보면, 아마존은 LLM(Large Language Model)과 생성형 AI 기술을 활용하여 광고 및 제품 추천 시스템을 고도화할 계획인 것으로 보입니다.\\n\\n구체적으로는 다음과 같은 방향으로 진행될 것으로 예상됩니다:\\n\\n1. LLM을 활용하여 고객의 검색 의도와 쇼핑 행동을 더 잘 이해하고, 이를 바탕으로 관련성 높은 광고와 제품을 추천하는 기능 개선\\n\\n2. 생성형 AI 모델을 활용하여 고객, 판매자, 브랜드, 크리에이터 등 다양한 이해관계자를 위한 맞춤형 경험 제공\\n\\n3. AWS 클라우드 상에서 LLM 및 생성형 AI 모델을 효율적으로 학습하고 운영할 수 있는 인프라 및 서비스 제공\\n\\n4. 개발자 생산성 향상을 위한 코드 제안 등 LLM 기반 개발자 도구 활용\\n\\n아마존은 이러한 LLM과 생성형 AI 기술 활용을 통해 고객 경험 혁신, 광고 효율 제고, 개발자 생산성 향상 등의 효과를 기대하고 있는 것으로 보입니다.')]), return_messages=True, human_prefix='User', ai_prefix='Assistant', memory_key='chat_history')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd648d4-0c63-4671-90c7-df628e84e03a",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17c60bb8-3fe0-4376-b1e3-5d81e1308f37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "summary_memory = ConversationSummaryMemory(\n",
    "    llm=llm,\n",
    "    human_prefix = 'User', \n",
    "    ai_prefix='Assistant', \n",
    "    memory_key='chat_history'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f79128a0-66ae-496f-9c56-6fb3e575d430",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'제프 베조스의 연례 주주 서한에서 언급된 내용을 종합해보면, 아마존은 LLM(Large Language Model)과 생성형 AI 기술을 활용하여 광고 및 제품 추천 시스템을 고도화할 계획인 것으로 보입니다.\\n\\n구체적으로는 다음과 같은 방향으로 진행될 것으로 예상됩니다:\\n\\n1. LLM을 활용하여 고객 경험 전반을 개선\\n- 검색, 제품 추천, 맞춤형 콘텐츠 생성 등에 LLM 기술 적용\\n\\n2. 광고 선정 알고리즘 개선\\n- 기계학습 기술로 광고 관련성을 높여 고객과 브랜드 모두에게 유용한 광고 제공\\n\\n3. 개발자 생산성 향상\\n- AWS CodeWhisperer 등 LLM 기반 코드 자동완성 기능 제공\\n\\n4. 기업 고객을 위한 LLM 서비스 제공\\n- AWS 클라우드 상에서 LLM 모델 학습/추론 환경 제공\\n\\n아마존은 LLM과 생성형 AI가 미래 혁신의 핵심 기술이 될 것으로 내다보고 있으며, 이를 통해 고객 경험 혁신과 새로운 수익원 창출을 모두 노리는 것으로 판단됩니다.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "conversation_with_retrieval = ConversationalRetrievalChain.from_llm(\n",
    "    llm, \n",
    "    index_from_loader.vectorstore.as_retriever(), \n",
    "    memory=summary_memory,\n",
    ")\n",
    "chat_response = conversation_with_retrieval.invoke({\"question\": input_text}) #사용자 메시지, 기록 및 지식을 모델에 전달합니다.\n",
    "\n",
    "chat_response['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158fce74-0952-4ec8-a965-b01ca4d53445",
   "metadata": {},
   "source": [
    "## condense_question_prompt + chain_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92c5f75d-8140-4241-a4fa-59e3d342a992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Define your system instruction\n",
    "system_instruction = \"The assistant should provide detailed explanations.\"\n",
    "\n",
    "# Define your template with the system instruction\n",
    "template = (\n",
    "    f\"{system_instruction} \"\n",
    "    \"Combine the chat history and follow up question into \"\n",
    "    \"a standalone question. Chat History: {chat_history}\"\n",
    "    \"Follow up question: {question}\"\n",
    ")\n",
    "\n",
    "# Create the prompt template\n",
    "condense_question_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "867966ad-3f3a-4e98-aa71-c0bdd0d8b391",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아마존이 LLM 기술을 광고 및 제품 추천 시스템에 적용하여 다음과 같은 방식으로 고도화할 것이라는 점을 잘 설명해주셨습니다:\\n\\n1. 고객 행동 및 의도 이해 개선\\n2. 동적 맞춤형 광고/추천 문구 생성 \\n3. 이미지, 비디오 등 멀티모달 데이터 활용\\n4. 지속적인 데이터 학습을 통한 모델 성능 향상\\n\\nLLM의 자연어 처리, 텍스트 생성, 멀티모달 데이터 처리 능력을 활용하여 고객 맞춤형 광고/추천의 관련성과 정확도를 크게 높일 수 있을 것으로 보입니다. 아마존의 방대한 고객 데이터와 LLM 기술을 결합하면 매우 강력한 개인화 시스템을 구축할 수 있을 것 같습니다. 지속적인 모델 개선으로 서비스 품질도 꾸준히 향상될 것으로 기대됩니다.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_retrieval = ConversationalRetrievalChain.from_llm(\n",
    "    llm, \n",
    "    index_from_loader.vectorstore.as_retriever(), \n",
    "    memory=memory,\n",
    "    condense_question_prompt=condense_question_prompt,\n",
    "    chain_type=\"stuff\"\n",
    ")\n",
    "chat_response = conversation_with_retrieval.invoke({\"question\": input_text}) #사용자 메시지, 기록 및 지식을 모델에 전달합니다.\n",
    "\n",
    "chat_response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67f0d6ef-0039-42d6-adc8-36a8a43f8bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferWindowMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='회사의 Generative AI 전략은 무엇인가요?'), AIMessage(content='아마존은 Generative AI, 특히 대규모 언어 모델(LLM)에 상당한 투자를 하고 있습니다. 주요 전략은 다음과 같습니다:\\n\\n1. 자체 LLM 개발 및 모든 고객 경험 개선을 위한 활용\\n아마존은 자체 LLM을 개발 중이며, 이를 통해 소비자, 판매자, 브랜드, 크리에이터 등 모든 고객 경험을 혁신하고자 합니다.\\n\\n2. AWS를 통한 Generative AI 민주화\\nAWS는 Trainium, Inferentia 등 가격 대비 성능이 우수한 ML 칩을 제공하여 기업들이 LLM을 저렴하게 학습하고 운영할 수 있도록 지원합니다. 또한 CodeWhisperer 등 Generative AI 애플리케이션도 제공합니다.\\n\\n3. 광고 및 추천 시스템 고도화\\n아마존은 LLM과 머신러닝을 활용하여 광고 및 제품 추천 알고리즘을 지속적으로 개선하고 있습니다.\\n\\n요약하면 아마존은 자체 LLM 개발, AWS 클라우드 서비스를 통한 Generative AI 민주화, 그리고 자사 서비스의 광고/추천 고도화를 위해 Generative AI에 적극 투자하고 있습니다.'), HumanMessage(content='LLM 기반 광고/추천 시스템 고도화에 대해 좀 더 자세히 알려줄 수 있어?'), AIMessage(content='제프 베조스의 연례 주주 서한에서 언급된 내용을 종합해보면, 아마존은 LLM(Large Language Model)과 생성형 AI 기술을 활용하여 광고 및 제품 추천 시스템을 고도화할 계획인 것으로 보입니다.\\n\\n구체적으로는 다음과 같은 방향으로 진행될 것으로 예상됩니다:\\n\\n1. LLM을 활용하여 고객의 검색 의도와 쇼핑 행동을 더 잘 이해하고, 이를 바탕으로 관련성 높은 광고와 제품을 추천하는 기능 개선\\n\\n2. 생성형 AI 모델을 활용하여 고객, 판매자, 브랜드, 크리에이터 등 다양한 이해관계자를 위한 맞춤형 경험 제공\\n\\n3. AWS 클라우드 상에서 LLM 및 생성형 AI 모델을 효율적으로 학습하고 운영할 수 있는 인프라 및 서비스 제공\\n\\n4. 개발자 생산성 향상을 위한 코드 제안 등 LLM 기반 개발자 도구 활용\\n\\n아마존은 이러한 LLM과 생성형 AI 기술 활용을 통해 고객 경험 혁신, 광고 효율 제고, 개발자 생산성 향상 등의 효과를 기대하고 있는 것으로 보입니다.'), HumanMessage(content='LLM 기반 광고/추천 시스템 고도화에 대해 좀 더 자세히 알려줄 수 있어?'), AIMessage(content='아마존이 LLM 기술을 광고 및 제품 추천 시스템에 적용하여 다음과 같은 방식으로 고도화할 것이라는 점을 잘 설명해주셨습니다:\\n\\n1. 고객 행동 및 의도 이해 개선\\n2. 동적 맞춤형 광고/추천 문구 생성 \\n3. 이미지, 비디오 등 멀티모달 데이터 활용\\n4. 지속적인 데이터 학습을 통한 모델 성능 향상\\n\\nLLM의 자연어 처리, 텍스트 생성, 멀티모달 데이터 처리 능력을 활용하여 고객 맞춤형 광고/추천의 관련성과 정확도를 크게 높일 수 있을 것으로 보입니다. 아마존의 방대한 고객 데이터와 LLM 기술을 결합하면 매우 강력한 개인화 시스템을 구축할 수 있을 것 같습니다. 지속적인 모델 개선으로 서비스 품질도 꾸준히 향상될 것으로 기대됩니다.')]), return_messages=True, human_prefix='User', ai_prefix='Assistant', memory_key='chat_history')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ad03f-5ab7-44c2-92cb-bf64ec88fc09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
